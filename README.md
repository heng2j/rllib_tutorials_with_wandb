# Hands-on RL with Ray’s RLlib + Weights & Biases

## Overview
“Hands-on RL with Ray’s RLlib” is a beginners tutorial for working with reinforcement learning (RL) environments, models, and algorithms using Ray’s RLlib library. It offers high scalability, a large list of algos to choose from (offline, model-based, model-free, etc..), support for TensorFlow and PyTorch, and a unified API for a variety of applications. This tutorial includes a brief introduction to provide an overview of concepts (e.g. why RL) before proceeding to RLlib models, hyperparameter tuning, debugging, student exercises, Q/A, and more. All code will be provided as .py files in a GitHub repo. 

## Intended Audience
* Python programmers who want to get started with reinforcement learning and RLlib

## Prerequisites
* Some Python programming experience
* Some familiarity with machine learning
* Experience in reinforcement learning and Ray would be helpful, but isn’t required
* Experience with TensorFlow or PyTorch would be helpful, but isn’t required

## Key Takeaways
* What is reinforcement learning and why RLlib
* How to configure and hyperparameter tune RLlib
* RLlib debugging best practices

## Tutorial Outline

## Other Recommended Readings
* [Attention Nets and More with RLlib's Trajectory View API](https://medium.com/distributed-computing-with-ray/attention-nets-and-more-with-rllibs-trajectory-view-api-d326339a6e65)
* [Intro to RLlib: Example Environments](https://medium.com/distributed-computing-with-ray/intro-to-rllib-example-environments-3a113f532c70)
* [Reinforcement Learning with RLlib in the Unity Game Engine](https://medium.com/distributed-computing-with-ray/reinforcement-learning-with-rllib-in-the-unity-game-engine-1a98080a7c0d)
